{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATE A FUNCTION TO EVALUATE THE MODEL BEFORE SENDING IT ONLINE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader\n",
    "# import sys\n",
    "# import os \n",
    "# # Add the project root directory to Python path\n",
    "# sys.path.append(os.path.dirname(os.getcwd()))\n",
    "# from data.dataset import Dataset\n",
    "# from models.dinov2_advanced import DinoV2Finetune_advanced\n",
    "# import hydra\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /users/eleves-b/2023/sylvain.dehayem-kenfouo/.cache/torch/hub/facebookresearch_dinov2_main\n"
     ]
    }
   ],
   "source": [
    "# #create the dataset with the test set\n",
    "# model=DinoV2Finetune_advanced()\n",
    "# checkpoint_path=[\n",
    "#     \"/users/eleves-b/2023/sylvain.dehayem-kenfouo/projet_final_modal/checkpoints/dinov2_advanced_2025-05-04_04-11-10_with_Gelu.pt\",\n",
    "#     \"/users/eleves-b/2023/sylvain.dehayem-kenfouo/projet_final_modal/checkpoints/dinov2_advanced_2025-05-04_03-20-35_with_Gelu.pt\", \n",
    "#     \"/users/eleves-b/2023/sylvain.dehayem-kenfouo/projet_final_modal/checkpoints/dinov2_advanced_2025-05-04_02-09-07_with_Gelu.pt\", \n",
    "#     \"/users/eleves-b/2023/sylvain.dehayem-kenfouo/projet_final_modal/checkpoints/dinov2_advanced_2025-05-03_06-12-30_last.pt\"\n",
    "\n",
    "# ]\n",
    "# def run_evaluation(model , checkpoint_path):\n",
    "#     @hydra.main(config_path=\"configs\", config_name=\"train\")\n",
    "#     def evaluate_model(cfg):\n",
    "#         test_dataset=Dataset(cfg.datamodule.dataset_path, \"test\", transforms=hydra.utils.instantiate(cfg.datamodule.test_transform), metadata=cfg.datamodule.metadata)\n",
    "#         test_loader=DataLoader(test_dataset, batch_size=cfg.datamodule.batch_size, shuffle=False, num_workers=cfg.datamodule.num_workers)\n",
    "#         loss_fn = hydra.utils.instantiate(cfg.loss_fn)\n",
    "#         model.load_state_dict(checkpoint)\n",
    "#         print(\"Model loaded\")\n",
    "#         for _, batch in enumerate(test_loader):\n",
    "#             batch[\"image\"] = batch[\"image\"].to(device)\n",
    "#             batch[\"target\"] = batch[\"target\"].to(device).squeeze()\n",
    "#             with torch.no_grad():\n",
    "#                 preds = model(batch).squeeze().cpu().numpy()\n",
    "#             loss = loss_fn(preds, batch[\"target\"])\n",
    "#             epoch_val_loss += loss.detach().cpu().numpy() * len(batch[\"image\"])\n",
    "#             num_samples_val += len(batch[\"image\"])\n",
    "#         epoch_val_loss /= num_samples_val\n",
    "#         val_metrics[\"val/loss_epoch\"] = epoch_val_loss\n",
    "#         logger_std.info(f\"----------------Epoch {epoch} val loss: {epoch_val_loss:.4f}----------------\")\n",
    "#     evaluate_model()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "\n",
      "Evaluating model with checkpoint: /users/eleves-b/2023/sylvain.dehayem-kenfouo/projet_final_modal/checkpoints/dinov2_advanced_2025-05-04_04-11-10_with_Gelu.pt \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4066991/1543475991.py:11: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"configs\", config_name=\"train\")\n",
      "usage: ipykernel_launcher.py [--help] [--hydra-help] [--version]\n",
      "                             [--cfg {job,hydra,all}] [--resolve]\n",
      "                             [--package PACKAGE] [--run] [--multirun]\n",
      "                             [--shell-completion] [--config-path CONFIG_PATH]\n",
      "                             [--config-name CONFIG_NAME]\n",
      "                             [--config-dir CONFIG_DIR]\n",
      "                             [--experimental-rerun EXPERIMENTAL_RERUN]\n",
      "                             [--info [{all,config,defaults,defaults-tree,plugins,searchpath}]]\n",
      "                             [overrides ...]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --f=/users/eleves-b/2023/sylvain.dehayem-kenfouo/.local/share/jupyter/runtime/kernel-v3f4ae586a2b334f24ff6d31705f6839e2b64f6f75.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-b/2023/sylvain.dehayem-kenfouo/miniconda/envs/challenge/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3678: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# for checkpoint in checkpoint_path:\n",
    "#     print(\"--------------------------------\\n\")\n",
    "#     print(f\"Evaluating model with checkpoint: {checkpoint} \\n\")\n",
    "#     run_evaluation(model, checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class DinoV2Finetune_large(nn.Module):\n",
    "    def __init__(self, frozen=False):\n",
    "        super().__init__()\n",
    "        self.backbone =torch.hub.load('facebookresearch/dinov2', 'dinov2_vitg14_reg')\n",
    "        self.backbone.head = nn.Identity()\n",
    "        self.dim = self.backbone.norm.normalized_shape[0]\n",
    "        if frozen:\n",
    "            for param in self.backbone.parameters():\n",
    "                param.requires_grad = False\n",
    "        self.regression_head = nn.Sequential(\n",
    "            nn.Linear(self.backbone.norm.normalized_shape[0], 1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x[\"image\"])\n",
    "        x = self.regression_head(x)\n",
    "        return x\n",
    "class DinoV2Finetune_small(nn.Module):\n",
    "    def __init__(self, frozen=False):\n",
    "        super().__init__()\n",
    "        self.backbone =torch.hub.load(\"facebookresearch/dinov2\", \"dinov2_vitb14_reg\")\n",
    "        self.backbone.head = nn.Identity()\n",
    "        self.dim = self.backbone.norm.normalized_shape[0]\n",
    "        if frozen:\n",
    "            for param in self.backbone.parameters():\n",
    "                param.requires_grad = False\n",
    "        self.regression_head = nn.Sequential(\n",
    "            nn.Linear(self.backbone.norm.normalized_shape[0], 1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x[\"image\"])\n",
    "        x = self.regression_head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /users/eleves-b/2023/sylvain.dehayem-kenfouo/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "Using cache found in /users/eleves-b/2023/sylvain.dehayem-kenfouo/.cache/torch/hub/facebookresearch_dinov2_main\n"
     ]
    }
   ],
   "source": [
    "large_dinov= DinoV2Finetune_large()\n",
    "small_dinov= DinoV2Finetune_small()\n",
    "#check parameters of the model\n",
    "# print(model.parameters())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary\n",
    "\n",
    "\n",
    "def print_model_info(model):\n",
    "    \"\"\"Print detailed information about the model\"\"\"\n",
    "    # Count parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "    print(f\"Frozen parameters: {total_params - trainable_params:,}\")\n",
    "    \n",
    "    # Print model architecture\n",
    "    print(\"\\nModel Architecture:\")\n",
    "    print(model)\n",
    "    \n",
    "    # Print parameter details for each layer\n",
    "    print(\"\\nDetailed Layer Information:\")\n",
    "    for name, param in model.named_parameters():\n",
    "        print(f\"{name}: shape={param.shape}, requires_grad={param.requires_grad}\")\n",
    "    \n",
    "    # # Print model summary with torchinfo\n",
    "    # print(\"\\nModel Summary:\")\n",
    "    # # Assuming input image size of 224x224 with batch size 2\n",
    "    # summary(model, input_data={\"image\": torch.zeros(2, 3, 224, 224)})\n",
    "\n",
    "\n",
    "def freeze_backbone(model, freeze=True):\n",
    "    \"\"\"Freeze or unfreeze the backbone parameters\"\"\"\n",
    "    for param in model.backbone.parameters():\n",
    "        param.requires_grad = not freeze\n",
    "    return model\n",
    "\n",
    "\n",
    "def replace_regression_head(model, new_layers):\n",
    "    \"\"\"Replace the regression head with a new sequence of layers\"\"\"\n",
    "    model.regression_head = nn.Sequential(*new_layers)\n",
    "    return model\n",
    "\n",
    "\n",
    "def change_output_dimension(model, output_dim):\n",
    "    \"\"\"Change the output dimension of the regression head\"\"\"\n",
    "    # Create a new regression head with the specified output dimension\n",
    "    new_head = nn.Sequential(\n",
    "        nn.Linear(model.dim, output_dim),\n",
    "        nn.ReLU(),\n",
    "    )\n",
    "    model.regression_head = new_head\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'large_dinov' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m size_in_mb\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Print the model size\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m model_size_mb = get_model_size(model=\u001b[43mlarge_dinov\u001b[49m)\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel size large: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_size_mb\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m MB\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m model_size_mb = get_model_size(model=small_dinov)\n",
      "\u001b[31mNameError\u001b[39m: name 'large_dinov' is not defined"
     ]
    }
   ],
   "source": [
    "# Calculate memory usage in MB\n",
    "def get_model_size(model):\n",
    "    param_size = 0\n",
    "    for param in model.parameters():\n",
    "        param_size += param.nelement() * param.element_size()\n",
    "    buffer_size = 0\n",
    "    for buffer in model.buffers():\n",
    "        buffer_size += buffer.nelement() * buffer.element_size()\n",
    "    size_in_mb = (param_size + buffer_size) / 1024**2\n",
    "    return size_in_mb\n",
    "\n",
    "# Print the model size\n",
    "model_size_mb = get_model_size(model=large_dinov)\n",
    "print(f\"Model size large: {model_size_mb:.2f} MB\")\n",
    "\n",
    "model_size_mb = get_model_size(model=small_dinov)\n",
    "print(f\"Model size small: {model_size_mb:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 1,136,488,449\n",
      "Trainable parameters: 1,136,488,449\n",
      "Frozen parameters: 0\n",
      "\n",
      "Model Architecture:\n",
      "DinoV2Finetune(\n",
      "  (backbone): DinoVisionTransformer(\n",
      "    (patch_embed): PatchEmbed(\n",
      "      (proj): Conv2d(3, 1536, kernel_size=(14, 14), stride=(14, 14))\n",
      "      (norm): Identity()\n",
      "    )\n",
      "    (blocks): ModuleList(\n",
      "      (0-39): 40 x NestedTensorBlock(\n",
      "        (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): MemEffAttention(\n",
      "          (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): SwiGLUFFNFused(\n",
      "          (w12): Linear(in_features=1536, out_features=8192, bias=True)\n",
      "          (w3): Linear(in_features=4096, out_features=1536, bias=True)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
      "    (head): Identity()\n",
      "  )\n",
      "  (regression_head): Sequential(\n",
      "    (0): Linear(in_features=1536, out_features=1, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      ")\n",
      "\n",
      "Detailed Layer Information:\n",
      "backbone.cls_token: shape=torch.Size([1, 1, 1536]), requires_grad=True\n",
      "backbone.pos_embed: shape=torch.Size([1, 1370, 1536]), requires_grad=True\n",
      "backbone.register_tokens: shape=torch.Size([1, 4, 1536]), requires_grad=True\n",
      "backbone.mask_token: shape=torch.Size([1, 1536]), requires_grad=True\n",
      "backbone.patch_embed.proj.weight: shape=torch.Size([1536, 3, 14, 14]), requires_grad=True\n",
      "backbone.patch_embed.proj.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.0.norm1.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.0.norm1.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.0.attn.qkv.weight: shape=torch.Size([4608, 1536]), requires_grad=True\n",
      "backbone.blocks.0.attn.qkv.bias: shape=torch.Size([4608]), requires_grad=True\n",
      "backbone.blocks.0.attn.proj.weight: shape=torch.Size([1536, 1536]), requires_grad=True\n",
      "backbone.blocks.0.attn.proj.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.0.ls1.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.0.norm2.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.0.norm2.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.0.mlp.w12.weight: shape=torch.Size([8192, 1536]), requires_grad=True\n",
      "backbone.blocks.0.mlp.w12.bias: shape=torch.Size([8192]), requires_grad=True\n",
      "backbone.blocks.0.mlp.w3.weight: shape=torch.Size([1536, 4096]), requires_grad=True\n",
      "backbone.blocks.0.mlp.w3.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.0.ls2.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.1.norm1.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.1.norm1.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.1.attn.qkv.weight: shape=torch.Size([4608, 1536]), requires_grad=True\n",
      "backbone.blocks.1.attn.qkv.bias: shape=torch.Size([4608]), requires_grad=True\n",
      "backbone.blocks.1.attn.proj.weight: shape=torch.Size([1536, 1536]), requires_grad=True\n",
      "backbone.blocks.1.attn.proj.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.1.ls1.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.1.norm2.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.1.norm2.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.1.mlp.w12.weight: shape=torch.Size([8192, 1536]), requires_grad=True\n",
      "backbone.blocks.1.mlp.w12.bias: shape=torch.Size([8192]), requires_grad=True\n",
      "backbone.blocks.1.mlp.w3.weight: shape=torch.Size([1536, 4096]), requires_grad=True\n",
      "backbone.blocks.1.mlp.w3.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.1.ls2.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.2.norm1.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.2.norm1.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.2.attn.qkv.weight: shape=torch.Size([4608, 1536]), requires_grad=True\n",
      "backbone.blocks.2.attn.qkv.bias: shape=torch.Size([4608]), requires_grad=True\n",
      "backbone.blocks.2.attn.proj.weight: shape=torch.Size([1536, 1536]), requires_grad=True\n",
      "backbone.blocks.2.attn.proj.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.2.ls1.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.2.norm2.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.2.norm2.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.2.mlp.w12.weight: shape=torch.Size([8192, 1536]), requires_grad=True\n",
      "backbone.blocks.2.mlp.w12.bias: shape=torch.Size([8192]), requires_grad=True\n",
      "backbone.blocks.2.mlp.w3.weight: shape=torch.Size([1536, 4096]), requires_grad=True\n",
      "backbone.blocks.2.mlp.w3.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.2.ls2.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.3.norm1.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.3.norm1.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.3.attn.qkv.weight: shape=torch.Size([4608, 1536]), requires_grad=True\n",
      "backbone.blocks.3.attn.qkv.bias: shape=torch.Size([4608]), requires_grad=True\n",
      "backbone.blocks.3.attn.proj.weight: shape=torch.Size([1536, 1536]), requires_grad=True\n",
      "backbone.blocks.3.attn.proj.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.3.ls1.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.3.norm2.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.3.norm2.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.3.mlp.w12.weight: shape=torch.Size([8192, 1536]), requires_grad=True\n",
      "backbone.blocks.3.mlp.w12.bias: shape=torch.Size([8192]), requires_grad=True\n",
      "backbone.blocks.3.mlp.w3.weight: shape=torch.Size([1536, 4096]), requires_grad=True\n",
      "backbone.blocks.3.mlp.w3.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.3.ls2.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.4.norm1.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.4.norm1.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.4.attn.qkv.weight: shape=torch.Size([4608, 1536]), requires_grad=True\n",
      "backbone.blocks.4.attn.qkv.bias: shape=torch.Size([4608]), requires_grad=True\n",
      "backbone.blocks.4.attn.proj.weight: shape=torch.Size([1536, 1536]), requires_grad=True\n",
      "backbone.blocks.4.attn.proj.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.4.ls1.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.4.norm2.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.4.norm2.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.4.mlp.w12.weight: shape=torch.Size([8192, 1536]), requires_grad=True\n",
      "backbone.blocks.4.mlp.w12.bias: shape=torch.Size([8192]), requires_grad=True\n",
      "backbone.blocks.4.mlp.w3.weight: shape=torch.Size([1536, 4096]), requires_grad=True\n",
      "backbone.blocks.4.mlp.w3.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.4.ls2.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.5.norm1.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.5.norm1.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.5.attn.qkv.weight: shape=torch.Size([4608, 1536]), requires_grad=True\n",
      "backbone.blocks.5.attn.qkv.bias: shape=torch.Size([4608]), requires_grad=True\n",
      "backbone.blocks.5.attn.proj.weight: shape=torch.Size([1536, 1536]), requires_grad=True\n",
      "backbone.blocks.5.attn.proj.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.5.ls1.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.5.norm2.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.5.norm2.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.5.mlp.w12.weight: shape=torch.Size([8192, 1536]), requires_grad=True\n",
      "backbone.blocks.5.mlp.w12.bias: shape=torch.Size([8192]), requires_grad=True\n",
      "backbone.blocks.5.mlp.w3.weight: shape=torch.Size([1536, 4096]), requires_grad=True\n",
      "backbone.blocks.5.mlp.w3.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.5.ls2.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.6.norm1.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.6.norm1.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.6.attn.qkv.weight: shape=torch.Size([4608, 1536]), requires_grad=True\n",
      "backbone.blocks.6.attn.qkv.bias: shape=torch.Size([4608]), requires_grad=True\n",
      "backbone.blocks.6.attn.proj.weight: shape=torch.Size([1536, 1536]), requires_grad=True\n",
      "backbone.blocks.6.attn.proj.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.6.ls1.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.6.norm2.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.6.norm2.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.6.mlp.w12.weight: shape=torch.Size([8192, 1536]), requires_grad=True\n",
      "backbone.blocks.6.mlp.w12.bias: shape=torch.Size([8192]), requires_grad=True\n",
      "backbone.blocks.6.mlp.w3.weight: shape=torch.Size([1536, 4096]), requires_grad=True\n",
      "backbone.blocks.6.mlp.w3.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.6.ls2.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.7.norm1.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.7.norm1.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.7.attn.qkv.weight: shape=torch.Size([4608, 1536]), requires_grad=True\n",
      "backbone.blocks.7.attn.qkv.bias: shape=torch.Size([4608]), requires_grad=True\n",
      "backbone.blocks.7.attn.proj.weight: shape=torch.Size([1536, 1536]), requires_grad=True\n",
      "backbone.blocks.7.attn.proj.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.7.ls1.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.7.norm2.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.7.norm2.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.7.mlp.w12.weight: shape=torch.Size([8192, 1536]), requires_grad=True\n",
      "backbone.blocks.7.mlp.w12.bias: shape=torch.Size([8192]), requires_grad=True\n",
      "backbone.blocks.7.mlp.w3.weight: shape=torch.Size([1536, 4096]), requires_grad=True\n",
      "backbone.blocks.7.mlp.w3.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.7.ls2.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.8.norm1.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.8.norm1.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.8.attn.qkv.weight: shape=torch.Size([4608, 1536]), requires_grad=True\n",
      "backbone.blocks.8.attn.qkv.bias: shape=torch.Size([4608]), requires_grad=True\n",
      "backbone.blocks.8.attn.proj.weight: shape=torch.Size([1536, 1536]), requires_grad=True\n",
      "backbone.blocks.8.attn.proj.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.8.ls1.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.8.norm2.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.8.norm2.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.8.mlp.w12.weight: shape=torch.Size([8192, 1536]), requires_grad=True\n",
      "backbone.blocks.8.mlp.w12.bias: shape=torch.Size([8192]), requires_grad=True\n",
      "backbone.blocks.8.mlp.w3.weight: shape=torch.Size([1536, 4096]), requires_grad=True\n",
      "backbone.blocks.8.mlp.w3.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.8.ls2.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.9.norm1.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.9.norm1.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.9.attn.qkv.weight: shape=torch.Size([4608, 1536]), requires_grad=True\n",
      "backbone.blocks.9.attn.qkv.bias: shape=torch.Size([4608]), requires_grad=True\n",
      "backbone.blocks.9.attn.proj.weight: shape=torch.Size([1536, 1536]), requires_grad=True\n",
      "backbone.blocks.9.attn.proj.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.9.ls1.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.9.norm2.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.9.norm2.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.9.mlp.w12.weight: shape=torch.Size([8192, 1536]), requires_grad=True\n",
      "backbone.blocks.9.mlp.w12.bias: shape=torch.Size([8192]), requires_grad=True\n",
      "backbone.blocks.9.mlp.w3.weight: shape=torch.Size([1536, 4096]), requires_grad=True\n",
      "backbone.blocks.9.mlp.w3.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.9.ls2.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.10.norm1.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.10.norm1.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.10.attn.qkv.weight: shape=torch.Size([4608, 1536]), requires_grad=True\n",
      "backbone.blocks.10.attn.qkv.bias: shape=torch.Size([4608]), requires_grad=True\n",
      "backbone.blocks.10.attn.proj.weight: shape=torch.Size([1536, 1536]), requires_grad=True\n",
      "backbone.blocks.10.attn.proj.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.10.ls1.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.10.norm2.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.10.norm2.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.10.mlp.w12.weight: shape=torch.Size([8192, 1536]), requires_grad=True\n",
      "backbone.blocks.10.mlp.w12.bias: shape=torch.Size([8192]), requires_grad=True\n",
      "backbone.blocks.10.mlp.w3.weight: shape=torch.Size([1536, 4096]), requires_grad=True\n",
      "backbone.blocks.10.mlp.w3.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.10.ls2.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.11.norm1.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.11.norm1.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.11.attn.qkv.weight: shape=torch.Size([4608, 1536]), requires_grad=True\n",
      "backbone.blocks.11.attn.qkv.bias: shape=torch.Size([4608]), requires_grad=True\n",
      "backbone.blocks.11.attn.proj.weight: shape=torch.Size([1536, 1536]), requires_grad=True\n",
      "backbone.blocks.11.attn.proj.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.11.ls1.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.11.norm2.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.11.norm2.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.11.mlp.w12.weight: shape=torch.Size([8192, 1536]), requires_grad=True\n",
      "backbone.blocks.11.mlp.w12.bias: shape=torch.Size([8192]), requires_grad=True\n",
      "backbone.blocks.11.mlp.w3.weight: shape=torch.Size([1536, 4096]), requires_grad=True\n",
      "backbone.blocks.11.mlp.w3.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.11.ls2.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.12.norm1.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.12.norm1.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.12.attn.qkv.weight: shape=torch.Size([4608, 1536]), requires_grad=True\n",
      "backbone.blocks.12.attn.qkv.bias: shape=torch.Size([4608]), requires_grad=True\n",
      "backbone.blocks.12.attn.proj.weight: shape=torch.Size([1536, 1536]), requires_grad=True\n",
      "backbone.blocks.12.attn.proj.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.12.ls1.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.12.norm2.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.12.norm2.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.12.mlp.w12.weight: shape=torch.Size([8192, 1536]), requires_grad=True\n",
      "backbone.blocks.12.mlp.w12.bias: shape=torch.Size([8192]), requires_grad=True\n",
      "backbone.blocks.12.mlp.w3.weight: shape=torch.Size([1536, 4096]), requires_grad=True\n",
      "backbone.blocks.12.mlp.w3.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.12.ls2.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.13.norm1.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.13.norm1.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.13.attn.qkv.weight: shape=torch.Size([4608, 1536]), requires_grad=True\n",
      "backbone.blocks.13.attn.qkv.bias: shape=torch.Size([4608]), requires_grad=True\n",
      "backbone.blocks.13.attn.proj.weight: shape=torch.Size([1536, 1536]), requires_grad=True\n",
      "backbone.blocks.13.attn.proj.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.13.ls1.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.13.norm2.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.13.norm2.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.13.mlp.w12.weight: shape=torch.Size([8192, 1536]), requires_grad=True\n",
      "backbone.blocks.13.mlp.w12.bias: shape=torch.Size([8192]), requires_grad=True\n",
      "backbone.blocks.13.mlp.w3.weight: shape=torch.Size([1536, 4096]), requires_grad=True\n",
      "backbone.blocks.13.mlp.w3.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.13.ls2.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.14.norm1.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.14.norm1.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.14.attn.qkv.weight: shape=torch.Size([4608, 1536]), requires_grad=True\n",
      "backbone.blocks.14.attn.qkv.bias: shape=torch.Size([4608]), requires_grad=True\n",
      "backbone.blocks.14.attn.proj.weight: shape=torch.Size([1536, 1536]), requires_grad=True\n",
      "backbone.blocks.14.attn.proj.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.14.ls1.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.14.norm2.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.14.norm2.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.14.mlp.w12.weight: shape=torch.Size([8192, 1536]), requires_grad=True\n",
      "backbone.blocks.14.mlp.w12.bias: shape=torch.Size([8192]), requires_grad=True\n",
      "backbone.blocks.14.mlp.w3.weight: shape=torch.Size([1536, 4096]), requires_grad=True\n",
      "backbone.blocks.14.mlp.w3.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.14.ls2.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.15.norm1.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.15.norm1.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.15.attn.qkv.weight: shape=torch.Size([4608, 1536]), requires_grad=True\n",
      "backbone.blocks.15.attn.qkv.bias: shape=torch.Size([4608]), requires_grad=True\n",
      "backbone.blocks.15.attn.proj.weight: shape=torch.Size([1536, 1536]), requires_grad=True\n",
      "backbone.blocks.15.attn.proj.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.15.ls1.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.15.norm2.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.15.norm2.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.15.mlp.w12.weight: shape=torch.Size([8192, 1536]), requires_grad=True\n",
      "backbone.blocks.15.mlp.w12.bias: shape=torch.Size([8192]), requires_grad=True\n",
      "backbone.blocks.15.mlp.w3.weight: shape=torch.Size([1536, 4096]), requires_grad=True\n",
      "backbone.blocks.15.mlp.w3.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.15.ls2.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.16.norm1.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.16.norm1.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.16.attn.qkv.weight: shape=torch.Size([4608, 1536]), requires_grad=True\n",
      "backbone.blocks.16.attn.qkv.bias: shape=torch.Size([4608]), requires_grad=True\n",
      "backbone.blocks.16.attn.proj.weight: shape=torch.Size([1536, 1536]), requires_grad=True\n",
      "backbone.blocks.16.attn.proj.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.16.ls1.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.16.norm2.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.16.norm2.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.16.mlp.w12.weight: shape=torch.Size([8192, 1536]), requires_grad=True\n",
      "backbone.blocks.16.mlp.w12.bias: shape=torch.Size([8192]), requires_grad=True\n",
      "backbone.blocks.16.mlp.w3.weight: shape=torch.Size([1536, 4096]), requires_grad=True\n",
      "backbone.blocks.16.mlp.w3.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.16.ls2.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.17.norm1.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.17.norm1.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.17.attn.qkv.weight: shape=torch.Size([4608, 1536]), requires_grad=True\n",
      "backbone.blocks.17.attn.qkv.bias: shape=torch.Size([4608]), requires_grad=True\n",
      "backbone.blocks.17.attn.proj.weight: shape=torch.Size([1536, 1536]), requires_grad=True\n",
      "backbone.blocks.17.attn.proj.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.17.ls1.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.17.norm2.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.17.norm2.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.17.mlp.w12.weight: shape=torch.Size([8192, 1536]), requires_grad=True\n",
      "backbone.blocks.17.mlp.w12.bias: shape=torch.Size([8192]), requires_grad=True\n",
      "backbone.blocks.17.mlp.w3.weight: shape=torch.Size([1536, 4096]), requires_grad=True\n",
      "backbone.blocks.17.mlp.w3.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.17.ls2.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.18.norm1.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.18.norm1.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.18.attn.qkv.weight: shape=torch.Size([4608, 1536]), requires_grad=True\n",
      "backbone.blocks.18.attn.qkv.bias: shape=torch.Size([4608]), requires_grad=True\n",
      "backbone.blocks.18.attn.proj.weight: shape=torch.Size([1536, 1536]), requires_grad=True\n",
      "backbone.blocks.18.attn.proj.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.18.ls1.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.18.norm2.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.18.norm2.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.18.mlp.w12.weight: shape=torch.Size([8192, 1536]), requires_grad=True\n",
      "backbone.blocks.18.mlp.w12.bias: shape=torch.Size([8192]), requires_grad=True\n",
      "backbone.blocks.18.mlp.w3.weight: shape=torch.Size([1536, 4096]), requires_grad=True\n",
      "backbone.blocks.18.mlp.w3.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.18.ls2.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.19.norm1.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.19.norm1.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.19.attn.qkv.weight: shape=torch.Size([4608, 1536]), requires_grad=True\n",
      "backbone.blocks.19.attn.qkv.bias: shape=torch.Size([4608]), requires_grad=True\n",
      "backbone.blocks.19.attn.proj.weight: shape=torch.Size([1536, 1536]), requires_grad=True\n",
      "backbone.blocks.19.attn.proj.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.19.ls1.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.19.norm2.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.19.norm2.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.19.mlp.w12.weight: shape=torch.Size([8192, 1536]), requires_grad=True\n",
      "backbone.blocks.19.mlp.w12.bias: shape=torch.Size([8192]), requires_grad=True\n",
      "backbone.blocks.19.mlp.w3.weight: shape=torch.Size([1536, 4096]), requires_grad=True\n",
      "backbone.blocks.19.mlp.w3.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.19.ls2.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.20.norm1.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.20.norm1.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.20.attn.qkv.weight: shape=torch.Size([4608, 1536]), requires_grad=True\n",
      "backbone.blocks.20.attn.qkv.bias: shape=torch.Size([4608]), requires_grad=True\n",
      "backbone.blocks.20.attn.proj.weight: shape=torch.Size([1536, 1536]), requires_grad=True\n",
      "backbone.blocks.20.attn.proj.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.20.ls1.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.20.norm2.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.20.norm2.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.20.mlp.w12.weight: shape=torch.Size([8192, 1536]), requires_grad=True\n",
      "backbone.blocks.20.mlp.w12.bias: shape=torch.Size([8192]), requires_grad=True\n",
      "backbone.blocks.20.mlp.w3.weight: shape=torch.Size([1536, 4096]), requires_grad=True\n",
      "backbone.blocks.20.mlp.w3.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.20.ls2.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.21.norm1.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.21.norm1.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.21.attn.qkv.weight: shape=torch.Size([4608, 1536]), requires_grad=True\n",
      "backbone.blocks.21.attn.qkv.bias: shape=torch.Size([4608]), requires_grad=True\n",
      "backbone.blocks.21.attn.proj.weight: shape=torch.Size([1536, 1536]), requires_grad=True\n",
      "backbone.blocks.21.attn.proj.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.21.ls1.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.21.norm2.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.21.norm2.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.21.mlp.w12.weight: shape=torch.Size([8192, 1536]), requires_grad=True\n",
      "backbone.blocks.21.mlp.w12.bias: shape=torch.Size([8192]), requires_grad=True\n",
      "backbone.blocks.21.mlp.w3.weight: shape=torch.Size([1536, 4096]), requires_grad=True\n",
      "backbone.blocks.21.mlp.w3.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.21.ls2.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.22.norm1.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.22.norm1.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.22.attn.qkv.weight: shape=torch.Size([4608, 1536]), requires_grad=True\n",
      "backbone.blocks.22.attn.qkv.bias: shape=torch.Size([4608]), requires_grad=True\n",
      "backbone.blocks.22.attn.proj.weight: shape=torch.Size([1536, 1536]), requires_grad=True\n",
      "backbone.blocks.22.attn.proj.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.22.ls1.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.22.norm2.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.22.norm2.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.22.mlp.w12.weight: shape=torch.Size([8192, 1536]), requires_grad=True\n",
      "backbone.blocks.22.mlp.w12.bias: shape=torch.Size([8192]), requires_grad=True\n",
      "backbone.blocks.22.mlp.w3.weight: shape=torch.Size([1536, 4096]), requires_grad=True\n",
      "backbone.blocks.22.mlp.w3.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.22.ls2.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.23.norm1.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.23.norm1.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.23.attn.qkv.weight: shape=torch.Size([4608, 1536]), requires_grad=True\n",
      "backbone.blocks.23.attn.qkv.bias: shape=torch.Size([4608]), requires_grad=True\n",
      "backbone.blocks.23.attn.proj.weight: shape=torch.Size([1536, 1536]), requires_grad=True\n",
      "backbone.blocks.23.attn.proj.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.23.ls1.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.23.norm2.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.23.norm2.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.23.mlp.w12.weight: shape=torch.Size([8192, 1536]), requires_grad=True\n",
      "backbone.blocks.23.mlp.w12.bias: shape=torch.Size([8192]), requires_grad=True\n",
      "backbone.blocks.23.mlp.w3.weight: shape=torch.Size([1536, 4096]), requires_grad=True\n",
      "backbone.blocks.23.mlp.w3.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.23.ls2.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.24.norm1.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.24.norm1.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.24.attn.qkv.weight: shape=torch.Size([4608, 1536]), requires_grad=True\n",
      "backbone.blocks.24.attn.qkv.bias: shape=torch.Size([4608]), requires_grad=True\n",
      "backbone.blocks.24.attn.proj.weight: shape=torch.Size([1536, 1536]), requires_grad=True\n",
      "backbone.blocks.24.attn.proj.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.24.ls1.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.24.norm2.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.24.norm2.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.24.mlp.w12.weight: shape=torch.Size([8192, 1536]), requires_grad=True\n",
      "backbone.blocks.24.mlp.w12.bias: shape=torch.Size([8192]), requires_grad=True\n",
      "backbone.blocks.24.mlp.w3.weight: shape=torch.Size([1536, 4096]), requires_grad=True\n",
      "backbone.blocks.24.mlp.w3.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.24.ls2.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.25.norm1.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.25.norm1.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.25.attn.qkv.weight: shape=torch.Size([4608, 1536]), requires_grad=True\n",
      "backbone.blocks.25.attn.qkv.bias: shape=torch.Size([4608]), requires_grad=True\n",
      "backbone.blocks.25.attn.proj.weight: shape=torch.Size([1536, 1536]), requires_grad=True\n",
      "backbone.blocks.25.attn.proj.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.25.ls1.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.25.norm2.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.25.norm2.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.25.mlp.w12.weight: shape=torch.Size([8192, 1536]), requires_grad=True\n",
      "backbone.blocks.25.mlp.w12.bias: shape=torch.Size([8192]), requires_grad=True\n",
      "backbone.blocks.25.mlp.w3.weight: shape=torch.Size([1536, 4096]), requires_grad=True\n",
      "backbone.blocks.25.mlp.w3.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.25.ls2.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.26.norm1.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.26.norm1.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.26.attn.qkv.weight: shape=torch.Size([4608, 1536]), requires_grad=True\n",
      "backbone.blocks.26.attn.qkv.bias: shape=torch.Size([4608]), requires_grad=True\n",
      "backbone.blocks.26.attn.proj.weight: shape=torch.Size([1536, 1536]), requires_grad=True\n",
      "backbone.blocks.26.attn.proj.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.26.ls1.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.26.norm2.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.26.norm2.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.26.mlp.w12.weight: shape=torch.Size([8192, 1536]), requires_grad=True\n",
      "backbone.blocks.26.mlp.w12.bias: shape=torch.Size([8192]), requires_grad=True\n",
      "backbone.blocks.26.mlp.w3.weight: shape=torch.Size([1536, 4096]), requires_grad=True\n",
      "backbone.blocks.26.mlp.w3.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.26.ls2.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.27.norm1.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.27.norm1.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.27.attn.qkv.weight: shape=torch.Size([4608, 1536]), requires_grad=True\n",
      "backbone.blocks.27.attn.qkv.bias: shape=torch.Size([4608]), requires_grad=True\n",
      "backbone.blocks.27.attn.proj.weight: shape=torch.Size([1536, 1536]), requires_grad=True\n",
      "backbone.blocks.27.attn.proj.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.27.ls1.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.27.norm2.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.27.norm2.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.27.mlp.w12.weight: shape=torch.Size([8192, 1536]), requires_grad=True\n",
      "backbone.blocks.27.mlp.w12.bias: shape=torch.Size([8192]), requires_grad=True\n",
      "backbone.blocks.27.mlp.w3.weight: shape=torch.Size([1536, 4096]), requires_grad=True\n",
      "backbone.blocks.27.mlp.w3.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.27.ls2.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.28.norm1.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.28.norm1.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.28.attn.qkv.weight: shape=torch.Size([4608, 1536]), requires_grad=True\n",
      "backbone.blocks.28.attn.qkv.bias: shape=torch.Size([4608]), requires_grad=True\n",
      "backbone.blocks.28.attn.proj.weight: shape=torch.Size([1536, 1536]), requires_grad=True\n",
      "backbone.blocks.28.attn.proj.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.28.ls1.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.28.norm2.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.28.norm2.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.28.mlp.w12.weight: shape=torch.Size([8192, 1536]), requires_grad=True\n",
      "backbone.blocks.28.mlp.w12.bias: shape=torch.Size([8192]), requires_grad=True\n",
      "backbone.blocks.28.mlp.w3.weight: shape=torch.Size([1536, 4096]), requires_grad=True\n",
      "backbone.blocks.28.mlp.w3.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.28.ls2.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.29.norm1.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.29.norm1.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.29.attn.qkv.weight: shape=torch.Size([4608, 1536]), requires_grad=True\n",
      "backbone.blocks.29.attn.qkv.bias: shape=torch.Size([4608]), requires_grad=True\n",
      "backbone.blocks.29.attn.proj.weight: shape=torch.Size([1536, 1536]), requires_grad=True\n",
      "backbone.blocks.29.attn.proj.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.29.ls1.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.29.norm2.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.29.norm2.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.29.mlp.w12.weight: shape=torch.Size([8192, 1536]), requires_grad=True\n",
      "backbone.blocks.29.mlp.w12.bias: shape=torch.Size([8192]), requires_grad=True\n",
      "backbone.blocks.29.mlp.w3.weight: shape=torch.Size([1536, 4096]), requires_grad=True\n",
      "backbone.blocks.29.mlp.w3.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.29.ls2.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.30.norm1.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.30.norm1.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.30.attn.qkv.weight: shape=torch.Size([4608, 1536]), requires_grad=True\n",
      "backbone.blocks.30.attn.qkv.bias: shape=torch.Size([4608]), requires_grad=True\n",
      "backbone.blocks.30.attn.proj.weight: shape=torch.Size([1536, 1536]), requires_grad=True\n",
      "backbone.blocks.30.attn.proj.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.30.ls1.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.30.norm2.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.30.norm2.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.30.mlp.w12.weight: shape=torch.Size([8192, 1536]), requires_grad=True\n",
      "backbone.blocks.30.mlp.w12.bias: shape=torch.Size([8192]), requires_grad=True\n",
      "backbone.blocks.30.mlp.w3.weight: shape=torch.Size([1536, 4096]), requires_grad=True\n",
      "backbone.blocks.30.mlp.w3.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.30.ls2.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.31.norm1.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.31.norm1.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.31.attn.qkv.weight: shape=torch.Size([4608, 1536]), requires_grad=True\n",
      "backbone.blocks.31.attn.qkv.bias: shape=torch.Size([4608]), requires_grad=True\n",
      "backbone.blocks.31.attn.proj.weight: shape=torch.Size([1536, 1536]), requires_grad=True\n",
      "backbone.blocks.31.attn.proj.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.31.ls1.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.31.norm2.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.31.norm2.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.31.mlp.w12.weight: shape=torch.Size([8192, 1536]), requires_grad=True\n",
      "backbone.blocks.31.mlp.w12.bias: shape=torch.Size([8192]), requires_grad=True\n",
      "backbone.blocks.31.mlp.w3.weight: shape=torch.Size([1536, 4096]), requires_grad=True\n",
      "backbone.blocks.31.mlp.w3.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.31.ls2.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.32.norm1.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.32.norm1.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.32.attn.qkv.weight: shape=torch.Size([4608, 1536]), requires_grad=True\n",
      "backbone.blocks.32.attn.qkv.bias: shape=torch.Size([4608]), requires_grad=True\n",
      "backbone.blocks.32.attn.proj.weight: shape=torch.Size([1536, 1536]), requires_grad=True\n",
      "backbone.blocks.32.attn.proj.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.32.ls1.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.32.norm2.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.32.norm2.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.32.mlp.w12.weight: shape=torch.Size([8192, 1536]), requires_grad=True\n",
      "backbone.blocks.32.mlp.w12.bias: shape=torch.Size([8192]), requires_grad=True\n",
      "backbone.blocks.32.mlp.w3.weight: shape=torch.Size([1536, 4096]), requires_grad=True\n",
      "backbone.blocks.32.mlp.w3.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.32.ls2.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.33.norm1.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.33.norm1.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.33.attn.qkv.weight: shape=torch.Size([4608, 1536]), requires_grad=True\n",
      "backbone.blocks.33.attn.qkv.bias: shape=torch.Size([4608]), requires_grad=True\n",
      "backbone.blocks.33.attn.proj.weight: shape=torch.Size([1536, 1536]), requires_grad=True\n",
      "backbone.blocks.33.attn.proj.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.33.ls1.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.33.norm2.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.33.norm2.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.33.mlp.w12.weight: shape=torch.Size([8192, 1536]), requires_grad=True\n",
      "backbone.blocks.33.mlp.w12.bias: shape=torch.Size([8192]), requires_grad=True\n",
      "backbone.blocks.33.mlp.w3.weight: shape=torch.Size([1536, 4096]), requires_grad=True\n",
      "backbone.blocks.33.mlp.w3.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.33.ls2.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.34.norm1.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.34.norm1.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.34.attn.qkv.weight: shape=torch.Size([4608, 1536]), requires_grad=True\n",
      "backbone.blocks.34.attn.qkv.bias: shape=torch.Size([4608]), requires_grad=True\n",
      "backbone.blocks.34.attn.proj.weight: shape=torch.Size([1536, 1536]), requires_grad=True\n",
      "backbone.blocks.34.attn.proj.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.34.ls1.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.34.norm2.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.34.norm2.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.34.mlp.w12.weight: shape=torch.Size([8192, 1536]), requires_grad=True\n",
      "backbone.blocks.34.mlp.w12.bias: shape=torch.Size([8192]), requires_grad=True\n",
      "backbone.blocks.34.mlp.w3.weight: shape=torch.Size([1536, 4096]), requires_grad=True\n",
      "backbone.blocks.34.mlp.w3.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.34.ls2.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.35.norm1.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.35.norm1.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.35.attn.qkv.weight: shape=torch.Size([4608, 1536]), requires_grad=True\n",
      "backbone.blocks.35.attn.qkv.bias: shape=torch.Size([4608]), requires_grad=True\n",
      "backbone.blocks.35.attn.proj.weight: shape=torch.Size([1536, 1536]), requires_grad=True\n",
      "backbone.blocks.35.attn.proj.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.35.ls1.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.35.norm2.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.35.norm2.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.35.mlp.w12.weight: shape=torch.Size([8192, 1536]), requires_grad=True\n",
      "backbone.blocks.35.mlp.w12.bias: shape=torch.Size([8192]), requires_grad=True\n",
      "backbone.blocks.35.mlp.w3.weight: shape=torch.Size([1536, 4096]), requires_grad=True\n",
      "backbone.blocks.35.mlp.w3.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.35.ls2.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.36.norm1.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.36.norm1.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.36.attn.qkv.weight: shape=torch.Size([4608, 1536]), requires_grad=True\n",
      "backbone.blocks.36.attn.qkv.bias: shape=torch.Size([4608]), requires_grad=True\n",
      "backbone.blocks.36.attn.proj.weight: shape=torch.Size([1536, 1536]), requires_grad=True\n",
      "backbone.blocks.36.attn.proj.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.36.ls1.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.36.norm2.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.36.norm2.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.36.mlp.w12.weight: shape=torch.Size([8192, 1536]), requires_grad=True\n",
      "backbone.blocks.36.mlp.w12.bias: shape=torch.Size([8192]), requires_grad=True\n",
      "backbone.blocks.36.mlp.w3.weight: shape=torch.Size([1536, 4096]), requires_grad=True\n",
      "backbone.blocks.36.mlp.w3.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.36.ls2.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.37.norm1.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.37.norm1.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.37.attn.qkv.weight: shape=torch.Size([4608, 1536]), requires_grad=True\n",
      "backbone.blocks.37.attn.qkv.bias: shape=torch.Size([4608]), requires_grad=True\n",
      "backbone.blocks.37.attn.proj.weight: shape=torch.Size([1536, 1536]), requires_grad=True\n",
      "backbone.blocks.37.attn.proj.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.37.ls1.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.37.norm2.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.37.norm2.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.37.mlp.w12.weight: shape=torch.Size([8192, 1536]), requires_grad=True\n",
      "backbone.blocks.37.mlp.w12.bias: shape=torch.Size([8192]), requires_grad=True\n",
      "backbone.blocks.37.mlp.w3.weight: shape=torch.Size([1536, 4096]), requires_grad=True\n",
      "backbone.blocks.37.mlp.w3.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.37.ls2.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.38.norm1.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.38.norm1.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.38.attn.qkv.weight: shape=torch.Size([4608, 1536]), requires_grad=True\n",
      "backbone.blocks.38.attn.qkv.bias: shape=torch.Size([4608]), requires_grad=True\n",
      "backbone.blocks.38.attn.proj.weight: shape=torch.Size([1536, 1536]), requires_grad=True\n",
      "backbone.blocks.38.attn.proj.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.38.ls1.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.38.norm2.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.38.norm2.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.38.mlp.w12.weight: shape=torch.Size([8192, 1536]), requires_grad=True\n",
      "backbone.blocks.38.mlp.w12.bias: shape=torch.Size([8192]), requires_grad=True\n",
      "backbone.blocks.38.mlp.w3.weight: shape=torch.Size([1536, 4096]), requires_grad=True\n",
      "backbone.blocks.38.mlp.w3.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.38.ls2.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.39.norm1.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.39.norm1.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.39.attn.qkv.weight: shape=torch.Size([4608, 1536]), requires_grad=True\n",
      "backbone.blocks.39.attn.qkv.bias: shape=torch.Size([4608]), requires_grad=True\n",
      "backbone.blocks.39.attn.proj.weight: shape=torch.Size([1536, 1536]), requires_grad=True\n",
      "backbone.blocks.39.attn.proj.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.39.ls1.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.39.norm2.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.39.norm2.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.39.mlp.w12.weight: shape=torch.Size([8192, 1536]), requires_grad=True\n",
      "backbone.blocks.39.mlp.w12.bias: shape=torch.Size([8192]), requires_grad=True\n",
      "backbone.blocks.39.mlp.w3.weight: shape=torch.Size([1536, 4096]), requires_grad=True\n",
      "backbone.blocks.39.mlp.w3.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.blocks.39.ls2.gamma: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.norm.weight: shape=torch.Size([1536]), requires_grad=True\n",
      "backbone.norm.bias: shape=torch.Size([1536]), requires_grad=True\n",
      "regression_head.0.weight: shape=torch.Size([1, 1536]), requires_grad=True\n",
      "regression_head.0.bias: shape=torch.Size([1]), requires_grad=True\n"
     ]
    }
   ],
   "source": [
    "print_model_info(model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VISUALIZE THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Load the dataset\n",
    "\n",
    "train_data=pd.read_csv(\"../dataset/train_val.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>channel</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>description</th>\n",
       "      <th>views</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>--2s6hjGrm4</td>\n",
       "      <td>UC-1rx8j9Ggp8mp4uD0ZdEIA</td>\n",
       "      <td>CGI &amp; VFX Breakdowns: \"Warzone\" - by Ramesh Th...</td>\n",
       "      <td>2020-12-15 05:00:01+00:00</td>\n",
       "      <td>Check out this revealing VFX Breakdown \"Warzon...</td>\n",
       "      <td>12299</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>--DnfroyKQ8</td>\n",
       "      <td>UC-1rx8j9Ggp8mp4uD0ZdEIA</td>\n",
       "      <td>A Sci-Fi Short Film: \"Exit\" - by Ng King Kwan ...</td>\n",
       "      <td>2020-07-01 16:00:00+00:00</td>\n",
       "      <td>TheCGBros Presents \"Exit\" by Ng King Kwan - Th...</td>\n",
       "      <td>7494</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>--aiU7VQKEw</td>\n",
       "      <td>UC-1rx8j9Ggp8mp4uD0ZdEIA</td>\n",
       "      <td>CGI 3D Animated Short: \"Lost Love\" - by Akash ...</td>\n",
       "      <td>2019-02-18 20:30:00+00:00</td>\n",
       "      <td>TheCGBros Presents \"Lost Love\" by Akash Manack...</td>\n",
       "      <td>11831</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>-0SrlZAvSVM</td>\n",
       "      <td>UCW6NyJ6oFLPTnx7iGRZXDDg</td>\n",
       "      <td>Jo Goes Hunting - Careful | Animated music vid...</td>\n",
       "      <td>2020-03-10 14:30:01+00:00</td>\n",
       "      <td>On the borderless map of a magical planet, lit...</td>\n",
       "      <td>2248</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>-13Y2Pe7kFs</td>\n",
       "      <td>UC-1rx8j9Ggp8mp4uD0ZdEIA</td>\n",
       "      <td>CGI VFX Breakdown: \"Logan (Wolverine): Digital...</td>\n",
       "      <td>2017-09-20 20:13:52+00:00</td>\n",
       "      <td>Check out this outstanding behind-the-scenes l...</td>\n",
       "      <td>113806</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>-1ElNi3aewU</td>\n",
       "      <td>UC-1rx8j9Ggp8mp4uD0ZdEIA</td>\n",
       "      <td>CGI 3D Animated Spot : \"Aroma\"  by - Space Patrol</td>\n",
       "      <td>2013-04-09 14:28:37+00:00</td>\n",
       "      <td>Here is another great 3D animated spot created...</td>\n",
       "      <td>6228</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13</td>\n",
       "      <td>-1FZlgerlnQ</td>\n",
       "      <td>UCXLfJIEp91L-fD0gP131IaQ</td>\n",
       "      <td>Hellevate Super Short Horror Comedy | Screamfest</td>\n",
       "      <td>2021-01-29 18:00:11+00:00</td>\n",
       "      <td>Hellevate is a super short horror comedy that ...</td>\n",
       "      <td>18652</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14</td>\n",
       "      <td>-1enK4XQvow</td>\n",
       "      <td>UC-1rx8j9Ggp8mp4uD0ZdEIA</td>\n",
       "      <td>CGI VFX Live Action Short Film: \"RELATIVITY\"  ...</td>\n",
       "      <td>2022-01-05 17:00:00+00:00</td>\n",
       "      <td>TheCGBros Presents  \"RELATIVITY\" by Guillaume ...</td>\n",
       "      <td>20409</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15</td>\n",
       "      <td>-1hANFUO3yc</td>\n",
       "      <td>UC-1rx8j9Ggp8mp4uD0ZdEIA</td>\n",
       "      <td>CGI VFX Short Films : \"TOB\" - by Andres Galeano</td>\n",
       "      <td>2014-03-18 00:31:30+00:00</td>\n",
       "      <td>Watch this VFX short Film, by the talented And...</td>\n",
       "      <td>10370</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16</td>\n",
       "      <td>-1nkzRrnVfA</td>\n",
       "      <td>UCW6NyJ6oFLPTnx7iGRZXDDg</td>\n",
       "      <td>Horror short film about a cursed cemetery | \"T...</td>\n",
       "      <td>2021-12-15 14:30:22+00:00</td>\n",
       "      <td>Sara and Ali are looking through photo's from ...</td>\n",
       "      <td>228067</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>17</td>\n",
       "      <td>-2G5aWo41FI</td>\n",
       "      <td>UCrSvhrtUgpZT3EU0x1Zoy-w</td>\n",
       "      <td>CGI Animated Short Film: \"The Hunter\" by Creat...</td>\n",
       "      <td>2020-09-23 21:26:31+00:00</td>\n",
       "      <td>CGI 3D Animated Short Film: The Hunter Animate...</td>\n",
       "      <td>679475</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>18</td>\n",
       "      <td>-2GXUooP7RA</td>\n",
       "      <td>UCrSvhrtUgpZT3EU0x1Zoy-w</td>\n",
       "      <td>CGI VFX - Making of - Azog - The Hobbit An Une...</td>\n",
       "      <td>2013-01-19 06:55:15+00:00</td>\n",
       "      <td>Watch more Making of, Behind the Scenes, Vfx B...</td>\n",
       "      <td>1463272</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>19</td>\n",
       "      <td>-2QKZNWHaiw</td>\n",
       "      <td>UCpUhcwq3oB7HKvrNeQmxJsg</td>\n",
       "      <td>Night Visit | Official Trailer</td>\n",
       "      <td>2023-02-02 22:55:43+00:00</td>\n",
       "      <td>Watch the Short Here - https://youtu.be/3ETt-S...</td>\n",
       "      <td>210</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>21</td>\n",
       "      <td>-2nyTzsnfrQ</td>\n",
       "      <td>UC-1rx8j9Ggp8mp4uD0ZdEIA</td>\n",
       "      <td>CGI 3D Animated Spot : \"Goodnight\" by - Studio...</td>\n",
       "      <td>2013-05-07 15:55:24+00:00</td>\n",
       "      <td>Check out this amazing and highly stylized 3D ...</td>\n",
       "      <td>8635</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>23</td>\n",
       "      <td>-33JjmUgM2A</td>\n",
       "      <td>UC-1rx8j9Ggp8mp4uD0ZdEIA</td>\n",
       "      <td>CGI 3D Animated Trailers: \"Monsters &amp; Dreams: ...</td>\n",
       "      <td>2019-09-05 04:00:00+00:00</td>\n",
       "      <td>Check out this awesome trailer \"Monsters &amp; Dre...</td>\n",
       "      <td>9947</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>24</td>\n",
       "      <td>-37nwIsz2BM</td>\n",
       "      <td>UC-1rx8j9Ggp8mp4uD0ZdEIA</td>\n",
       "      <td>CGI VFX Making Of :: \"Cross Climate\" - by Unit...</td>\n",
       "      <td>2015-10-05 03:30:00+00:00</td>\n",
       "      <td>Check out the great character animation and VF...</td>\n",
       "      <td>12760</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>25</td>\n",
       "      <td>-38KYLeEfHU</td>\n",
       "      <td>UC71x8bBOwIEscxAltguHXMQ</td>\n",
       "      <td>Casting for 'What Happened to Kali'</td>\n",
       "      <td>2018-09-07 22:05:07+00:00</td>\n",
       "      <td>What Happened to Kali is a short film project ...</td>\n",
       "      <td>640</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>27</td>\n",
       "      <td>-4eq9OGlkYw</td>\n",
       "      <td>UC-1rx8j9Ggp8mp4uD0ZdEIA</td>\n",
       "      <td>CGI 3D Animated Short: \"Capture\"  - by Yu-Ju Chen</td>\n",
       "      <td>2018-06-29 17:47:32+00:00</td>\n",
       "      <td>TheCGBros Presents \"Capture\" - This photo boot...</td>\n",
       "      <td>7535</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>28</td>\n",
       "      <td>-5Yye_6--lk</td>\n",
       "      <td>UCrSvhrtUgpZT3EU0x1Zoy-w</td>\n",
       "      <td>CGI 3D Making of HD \"Making of EXODE Short Fil...</td>\n",
       "      <td>2016-03-18 10:29:43+00:00</td>\n",
       "      <td>Making of EXODE Short Film by Kathleen Cartier...</td>\n",
       "      <td>29047</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>29</td>\n",
       "      <td>-5cvOGIezgc</td>\n",
       "      <td>UCiCnPY--pbn5S8JkJdV2PbQ</td>\n",
       "      <td>Chaoya Paoya |   - Bengali Movie Par...</td>\n",
       "      <td>2011-05-31 14:28:58+00:00</td>\n",
       "      <td>The Bengali Film Chaoya Paoya :   ...</td>\n",
       "      <td>58473</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0           id                   channel  \\\n",
       "0            0  --2s6hjGrm4  UC-1rx8j9Ggp8mp4uD0ZdEIA   \n",
       "1            1  --DnfroyKQ8  UC-1rx8j9Ggp8mp4uD0ZdEIA   \n",
       "2            2  --aiU7VQKEw  UC-1rx8j9Ggp8mp4uD0ZdEIA   \n",
       "3            6  -0SrlZAvSVM  UCW6NyJ6oFLPTnx7iGRZXDDg   \n",
       "4           10  -13Y2Pe7kFs  UC-1rx8j9Ggp8mp4uD0ZdEIA   \n",
       "5           12  -1ElNi3aewU  UC-1rx8j9Ggp8mp4uD0ZdEIA   \n",
       "6           13  -1FZlgerlnQ  UCXLfJIEp91L-fD0gP131IaQ   \n",
       "7           14  -1enK4XQvow  UC-1rx8j9Ggp8mp4uD0ZdEIA   \n",
       "8           15  -1hANFUO3yc  UC-1rx8j9Ggp8mp4uD0ZdEIA   \n",
       "9           16  -1nkzRrnVfA  UCW6NyJ6oFLPTnx7iGRZXDDg   \n",
       "10          17  -2G5aWo41FI  UCrSvhrtUgpZT3EU0x1Zoy-w   \n",
       "11          18  -2GXUooP7RA  UCrSvhrtUgpZT3EU0x1Zoy-w   \n",
       "12          19  -2QKZNWHaiw  UCpUhcwq3oB7HKvrNeQmxJsg   \n",
       "13          21  -2nyTzsnfrQ  UC-1rx8j9Ggp8mp4uD0ZdEIA   \n",
       "14          23  -33JjmUgM2A  UC-1rx8j9Ggp8mp4uD0ZdEIA   \n",
       "15          24  -37nwIsz2BM  UC-1rx8j9Ggp8mp4uD0ZdEIA   \n",
       "16          25  -38KYLeEfHU  UC71x8bBOwIEscxAltguHXMQ   \n",
       "17          27  -4eq9OGlkYw  UC-1rx8j9Ggp8mp4uD0ZdEIA   \n",
       "18          28  -5Yye_6--lk  UCrSvhrtUgpZT3EU0x1Zoy-w   \n",
       "19          29  -5cvOGIezgc  UCiCnPY--pbn5S8JkJdV2PbQ   \n",
       "\n",
       "                                                title  \\\n",
       "0   CGI & VFX Breakdowns: \"Warzone\" - by Ramesh Th...   \n",
       "1   A Sci-Fi Short Film: \"Exit\" - by Ng King Kwan ...   \n",
       "2   CGI 3D Animated Short: \"Lost Love\" - by Akash ...   \n",
       "3   Jo Goes Hunting - Careful | Animated music vid...   \n",
       "4   CGI VFX Breakdown: \"Logan (Wolverine): Digital...   \n",
       "5   CGI 3D Animated Spot : \"Aroma\"  by - Space Patrol   \n",
       "6    Hellevate Super Short Horror Comedy | Screamfest   \n",
       "7   CGI VFX Live Action Short Film: \"RELATIVITY\"  ...   \n",
       "8     CGI VFX Short Films : \"TOB\" - by Andres Galeano   \n",
       "9   Horror short film about a cursed cemetery | \"T...   \n",
       "10  CGI Animated Short Film: \"The Hunter\" by Creat...   \n",
       "11  CGI VFX - Making of - Azog - The Hobbit An Une...   \n",
       "12                     Night Visit | Official Trailer   \n",
       "13  CGI 3D Animated Spot : \"Goodnight\" by - Studio...   \n",
       "14  CGI 3D Animated Trailers: \"Monsters & Dreams: ...   \n",
       "15  CGI VFX Making Of :: \"Cross Climate\" - by Unit...   \n",
       "16                Casting for 'What Happened to Kali'   \n",
       "17  CGI 3D Animated Short: \"Capture\"  - by Yu-Ju Chen   \n",
       "18  CGI 3D Making of HD \"Making of EXODE Short Fil...   \n",
       "19  Chaoya Paoya |   - Bengali Movie Par...   \n",
       "\n",
       "                         date  \\\n",
       "0   2020-12-15 05:00:01+00:00   \n",
       "1   2020-07-01 16:00:00+00:00   \n",
       "2   2019-02-18 20:30:00+00:00   \n",
       "3   2020-03-10 14:30:01+00:00   \n",
       "4   2017-09-20 20:13:52+00:00   \n",
       "5   2013-04-09 14:28:37+00:00   \n",
       "6   2021-01-29 18:00:11+00:00   \n",
       "7   2022-01-05 17:00:00+00:00   \n",
       "8   2014-03-18 00:31:30+00:00   \n",
       "9   2021-12-15 14:30:22+00:00   \n",
       "10  2020-09-23 21:26:31+00:00   \n",
       "11  2013-01-19 06:55:15+00:00   \n",
       "12  2023-02-02 22:55:43+00:00   \n",
       "13  2013-05-07 15:55:24+00:00   \n",
       "14  2019-09-05 04:00:00+00:00   \n",
       "15  2015-10-05 03:30:00+00:00   \n",
       "16  2018-09-07 22:05:07+00:00   \n",
       "17  2018-06-29 17:47:32+00:00   \n",
       "18  2016-03-18 10:29:43+00:00   \n",
       "19  2011-05-31 14:28:58+00:00   \n",
       "\n",
       "                                          description    views  year  \n",
       "0   Check out this revealing VFX Breakdown \"Warzon...    12299  2020  \n",
       "1   TheCGBros Presents \"Exit\" by Ng King Kwan - Th...     7494  2020  \n",
       "2   TheCGBros Presents \"Lost Love\" by Akash Manack...    11831  2019  \n",
       "3   On the borderless map of a magical planet, lit...     2248  2020  \n",
       "4   Check out this outstanding behind-the-scenes l...   113806  2017  \n",
       "5   Here is another great 3D animated spot created...     6228  2013  \n",
       "6   Hellevate is a super short horror comedy that ...    18652  2021  \n",
       "7   TheCGBros Presents  \"RELATIVITY\" by Guillaume ...    20409  2022  \n",
       "8   Watch this VFX short Film, by the talented And...    10370  2014  \n",
       "9   Sara and Ali are looking through photo's from ...   228067  2021  \n",
       "10  CGI 3D Animated Short Film: The Hunter Animate...   679475  2020  \n",
       "11  Watch more Making of, Behind the Scenes, Vfx B...  1463272  2013  \n",
       "12  Watch the Short Here - https://youtu.be/3ETt-S...      210  2023  \n",
       "13  Check out this amazing and highly stylized 3D ...     8635  2013  \n",
       "14  Check out this awesome trailer \"Monsters & Dre...     9947  2019  \n",
       "15  Check out the great character animation and VF...    12760  2015  \n",
       "16  What Happened to Kali is a short film project ...      640  2018  \n",
       "17  TheCGBros Presents \"Capture\" - This photo boot...     7535  2018  \n",
       "18  Making of EXODE Short Film by Kathleen Cartier...    29047  2016  \n",
       "19  The Bengali Film Chaoya Paoya :   ...    58473  2011  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchvision\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtransforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransforms\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[32m      6\u001b[39m train_data_path=\u001b[33m\"\u001b[39m\u001b[33mCSC_43M04_EP_challenge/dataset\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      7\u001b[39m train_transformers=transforms.Compose([\n\u001b[32m      8\u001b[39m     transforms.Resize((\u001b[32m224\u001b[39m,\u001b[32m224\u001b[39m)), \n\u001b[32m      9\u001b[39m     transforms.RandomHorizontalFlip(),\n\u001b[32m     10\u001b[39m     transforms.ToTensor(),\n\u001b[32m     11\u001b[39m     transforms.Normalize(mean=[\u001b[32m0.485\u001b[39m, \u001b[32m0.456\u001b[39m, \u001b[32m0.406\u001b[39m], std=[\u001b[32m0.229\u001b[39m, \u001b[32m0.224\u001b[39m, \u001b[32m0.225\u001b[39m])\n\u001b[32m     12\u001b[39m ])\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'data'"
     ]
    }
   ],
   "source": [
    "#load the train dataset\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from data.dataset import Dataset\n",
    "\n",
    "train_data_path=\"CSC_43M04_EP_challenge/dataset\"\n",
    "train_transformers=transforms.Compose([\n",
    "    transforms.Resize((224,224)), \n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_set=Dataset(train_data_path, \"train_val\", train_transformers, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading image from: dataset/train_val/--2s6hjGrm4.jpg\n",
      "Error: Image file not found at dataset/train_val/--2s6hjGrm4.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define function to load and display an image\n",
    "def load_and_display_image(image_id):\n",
    "    image_path = os.path.join(\"dataset\", \"train_val\", f\"{image_id}.jpg\")\n",
    "    print(f\"Loading image from: {image_path}\")\n",
    "    \n",
    "    if os.path.exists(image_path):\n",
    "        img = Image.open(image_path).convert(\"RGB\")\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"Image ID: {image_id}\")\n",
    "        plt.show()\n",
    "        return img\n",
    "    else:\n",
    "        print(f\"Error: Image file not found at {image_path}\")\n",
    "        return None\n",
    "\n",
    "# Example: load the first image from your DataFrame\n",
    "first_image_id = train_data['id'].iloc[0]  # Gets the ID of the first row\n",
    "img = load_and_display_image(first_image_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRY TO PERFORM INFERENCE ON THE TRAINED MODEL AND THE LARGEST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: filelock in /users/eleves-b/2023/sylvain.dehayem-kenfouo/miniconda/envs/challenge/lib/python3.12/site-packages (from transformers) (3.18.0)\n",
      "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /users/eleves-b/2023/sylvain.dehayem-kenfouo/miniconda/envs/challenge/lib/python3.12/site-packages (from transformers) (2.2.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /users/eleves-b/2023/sylvain.dehayem-kenfouo/miniconda/envs/challenge/lib/python3.12/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /users/eleves-b/2023/sylvain.dehayem-kenfouo/miniconda/envs/challenge/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /users/eleves-b/2023/sylvain.dehayem-kenfouo/miniconda/envs/challenge/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /users/eleves-b/2023/sylvain.dehayem-kenfouo/miniconda/envs/challenge/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /users/eleves-b/2023/sylvain.dehayem-kenfouo/miniconda/envs/challenge/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /users/eleves-b/2023/sylvain.dehayem-kenfouo/miniconda/envs/challenge/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /users/eleves-b/2023/sylvain.dehayem-kenfouo/miniconda/envs/challenge/lib/python3.12/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /users/eleves-b/2023/sylvain.dehayem-kenfouo/miniconda/envs/challenge/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /users/eleves-b/2023/sylvain.dehayem-kenfouo/miniconda/envs/challenge/lib/python3.12/site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /users/eleves-b/2023/sylvain.dehayem-kenfouo/miniconda/envs/challenge/lib/python3.12/site-packages (from requests->transformers) (2025.4.26)\n",
      "Downloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (796 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m796.9/796.9 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Installing collected packages: safetensors, regex, huggingface-hub, tokenizers, transformers\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m5/5\u001b[0m [transformers][0m [transformers]ub]\n",
      "\u001b[1A\u001b[2KSuccessfully installed huggingface-hub-0.30.2 regex-2024.11.6 safetensors-0.5.3 tokenizers-0.21.1 transformers-4.51.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# ----- Config -----\n",
    "pretrained_model = \"prajjwal1/bert-tiny\"  # Very small model!\n",
    "num_classes = 2\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ----- Dummy Dataset -----\n",
    "texts = [\n",
    "    \"I love this movie!\",     # pos\n",
    "    \"This was awesome\",       # pos\n",
    "    \"I hate this film\",       # neg\n",
    "    \"Terrible experience\",    # neg\n",
    "    \"Brilliant performance\",  # pos\n",
    "    \"Awful and boring\"        # neg\n",
    "]\n",
    "labels = [1, 1, 0, 0, 1, 0]\n",
    "\n",
    "class ToyDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=32):\n",
    "        self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=max_length, return_tensors=\"pt\")\n",
    "        self.labels = torch.tensor(labels)\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "# ----- Custom Model -----\n",
    "class MyCustomLLM(nn.Module):\n",
    "    def __init__(self, base_model_path, num_classes):\n",
    "        super().__init__()\n",
    "        self.backbone = AutoModel.from_pretrained(base_model_path)\n",
    "        hidden_size = self.backbone.config.hidden_size\n",
    "        self.classifier = nn.Linear(hidden_size, num_classes)\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output = self.backbone(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled = output.last_hidden_state[:, 0]  # CLS token\n",
    "        return self.classifier(pooled)\n",
    "\n",
    "# ----- Prepare -----\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model)\n",
    "dataset = ToyDataset(texts, labels, tokenizer)\n",
    "loader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "model = MyCustomLLM(pretrained_model, num_classes).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# ----- Training Function -----\n",
    "def train_one_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits = model(input_ids, attention_mask)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# ----- Inference/Prediction -----\n",
    "def predict(model, texts):\n",
    "    model.eval()\n",
    "    encoded = tokenizer(texts, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(encoded['input_ids'], encoded['attention_mask'])\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        preds = probs.argmax(dim=1)\n",
    "    return preds.cpu().tolist(), probs.cpu().tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions before training:\n",
      "I love this movie! -> negative\n",
      "This was awesome -> positive\n",
      "I hate this film -> negative\n",
      "Terrible experience -> positive\n",
      "Brilliant performance -> positive\n",
      "Awful and boring -> negative\n",
      "Epoch 1 Loss: 0.5483\n",
      "Epoch 2 Loss: 0.6986\n",
      "Epoch 3 Loss: 0.6109\n",
      "Epoch 4 Loss: 0.5144\n",
      "Epoch 5 Loss: 0.4636\n",
      "\n",
      "Predictions after training:\n",
      "I love this movie! -> positive\n",
      "This was awesome -> positive\n",
      "I hate this film -> negative\n",
      "Terrible experience -> negative\n",
      "Brilliant performance -> positive\n",
      "Awful and boring -> negative\n"
     ]
    }
   ],
   "source": [
    "# ----- Before Training -----\n",
    "print(\"Predictions before training:\")\n",
    "preds, probs = predict(model, texts)\n",
    "for t,p in zip(texts, preds):\n",
    "    print(f\"{t} -> {'positive' if p==1 else 'negative'}\")\n",
    "\n",
    "# ----- Training -----\n",
    "for epoch in range(5):\n",
    "    loss = train_one_epoch(model, loader, optimizer, criterion)\n",
    "    print(f\"Epoch {epoch+1} Loss: {loss:.4f}\")\n",
    "\n",
    "# ----- After Training -----\n",
    "print(\"\\nPredictions after training:\")\n",
    "preds, probs = predict(model, texts)\n",
    "for t,p in zip(texts, preds):\n",
    "    print(f\"{t} -> {'positive' if p==1 else 'negative'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (challenge)",
   "language": "python",
   "name": "challenge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
